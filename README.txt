Name: Jeffrey Mattos-Arpilleda
Class: EE 104
Demonstration Link: https://www.youtube.com/watch?v=0eWf5P_vtag
Reference: 
https://sjsu.instructure.com/courses/1559910/modules

CNN BaseLine Code:
This Python script trains a convolutional neural network (CNN) to classify images from the CIFAR-10 dataset using TensorFlow and Keras. The dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.

The script performs the following tasks:

Import necessary libraries and modules.
Disable SSL certificate verification to allow loading the CIFAR-10 dataset.
Load the CIFAR-10 dataset and normalize pixel values.
Visualize the dataset to ensure it's loaded correctly.
Define data augmentation techniques to improve the model's performance.
Build the CNN model architecture.
Compile the model with the Stochastic Gradient Descent (SGD) optimizer and Sparse Categorical Crossentropy loss function.
Train the model on the training dataset with 100 epochs and validate it on the test dataset.
Plot the training and validation accuracy over the epochs.
Evaluate the model on the test dataset and print the test accuracy

Chatgpt Clone:
This Python script uses the OpenAI API to interact with GPT-3.5-turbo, a powerful language model. The script allows users to ask questions and receive responses generated by the model.

The script performs the following tasks:

Import necessary libraries and modules.
Load environment variables (if using the python-dotenv package).
Set the OpenAI API key. Replace the "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" with your own API key.
Define a function generate_response(prompt) to interact with the GPT-3.5-turbo model:
a. Set the model engine to "text-davinci-002".
b. Create a completion request with the provided prompt, setting the number of tokens, the number of responses, and the temperature.
c. Extract the generated text from the response and return it.
Run a loop that allows users to input questions and receive generated responses from the GPT-3.5-turbo model until the user types "quitme".
Remember to install the required packages by running the following commands:
pip install pandas openai
pip install python-dotenv

Additionally, the script includes a comment with information about GPT-3.5 models, their capabilities, and usage recommendations.

Documentation from Chatgpt Clone:
Tested the phrase: "How many colors are there in the world?"
Model: text-davinci-002 and text-davinci-003
Response: Both responded with the similar results, however 002's model added a theory that there could be infinte color possibilities. 

Changing the max_tokens doesn't really have that big of an effect on the results as the questions being asked do not use up as many tokens from 4000 to 1024.
Changing the temperature from a higher value (0.9) to a lower one (0.1) changes the expected output result that our AI gives us. For example, when asked what is the importance of a banana, we get a simplified reason as to why it is good at 0.1, vs. when using 0.9 we see a more educated reason for why we need bananas.

-changing model can change the output of what the model AI will respond with, however sometimes you will get the same result
-max_tokens limit the length of the response with a max of 4000 tokens, however the model doesn't necessarily need to use all the given token limit
-n represents number of responses to be requested, however similar to above if the model wants to give a single response it can.
-stop represents a specific stopping token, and in this case since there is no stopping token the generated response will continue until max token limit or model decides to stop generating text
-temperature controls the randomness of the generated output, with higher making it more random and lower making it more focused and deterministic.
-prompt is just to call for the variable prompt as an f-string input. This is how we are able to prompt the user to ask a question for the AI to solve.

Test-image.py:
This Python script demonstrates how to use a trained CIFAR-10 model to classify images fetched from the internet. The script performs the following tasks:

Disable SSL certificate verification (not recommended for production environments).
Import necessary libraries and modules.
Define the class names for the CIFAR-10 dataset.
Define a function load_image(filename) to load an image, resize it to 32x32 pixels, convert it to an array, and normalize pixel values to the range [0, 1].
Load the trained CIFAR-10 model from the 'MyGroup_CIFARmodel.h5' file.
For each image URL provided:
a. Download the image using TensorFlow's get_file() function.
b. Load the image using the load_image() function.
c. Predict the class of the image using the trained CIFAR-10 model.
d. Display the image using matplotlib.pyplot.
e. Print the predicted class name of the image.
The script classifies five different images fetched from the internet using the trained CIFAR-10 model. The images include an airplane, a cat, a horse, a ship, and a truck.

